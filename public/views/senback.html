<!DOCTYPE html>
<html lang="en">

<head>
    <title>adam optimizer - visNLP</title>
    <link rel="stylesheet" href="../style.css" />
</head>

<body>
    <div id="navbar">
        <button class="navelement" id="homenav" onclick="window.location='/'">
          <img src="assets/wpi_logo_transparent_white.png" alt="wpi logo2" class="nav-button-icon">
          <h1>visNLP 2.0 Home</h1>
        </button>
        <button class="navelement"        onclick="window.location='/w2v'"       ><h1>Word2Vec</h1></button>
        <button class="navelement-curr"   onclick="window.location='/senback'"   ><h1>Sen2Vec</h1></button>
        <button class="navelement"        onclick="window.location='/paraback'"  ><h1>Para2Vec</h1></button>
        <button class="navelement"        onclick="window.location='/adam'"      ><h1>Adam Optimizer</h1></button>
        <button class="navelement"        onclick="window.location='/songback'"  ><h1>Songs Recs App</h1></button>
        <button class="navelement"        onclick="window.location='/newsback'"  ><h1>Fake News App</h1></button>
    </div>

    <div id="sidebar_adam">
        <button id="switch_adam_button" onclick="window.location='/s2v'">
            <h1>Sen2Vec Step-by-Step Simulation</h1>
        </button>
        
        <div style="height:6vh;"></div>
        <div class="sidebar-web-diagram">
            <img src="/assets/web_diagrams/web_diagram_condensed_sen2vec.png" alt="adam web diagram">
        </div>
        <div style="height:8vh;"></div>

        <button class="prev-topic-button" onclick="window.location='/w2v'">
            <h2>Prev:</h2>
            <h1>Word2Vec</h1>
        </button>
        <button class="next-topic-button" onclick="window.location='/paraback'">
            <h2>Next:</h2>
            <h1>Para2Vec</h1>
        </button>
    </div>

    <div id="restofpage_overview">
        <!-- title -->
        <h1> Sentence2Vec </h1>

        <!-- content sec | TOPIC RUNDOWN -->
        <h2> Introduction to the Sentence2vec Algorithm </h2>

        <p> Sentence embedding, also known as Sen2Vec, is a powerful technique in natural language processing that 
            represents text data as a dense numerical vector. This approach allows for the application of machine learning 
            algorithms to text data, enabling tasks such as sentiment analysis, text classification, and information 
            retrieval. Sen2Vec is especially useful for NLP applications where the meaning of text is more important 
            than its surface level characteristics, such as spelling and grammar. </p>

        <p> Sen2Vec is based on the idea that words and sentences with similar meanings are often used in similar contexts.
            The technique involves training a machine learning model to predict the context of a given word or sentence, and 
            then using the learned representation of that context as the sentence embedding. This approach is similar to word 
            embedding, but instead of representing individual words, the embedding represents the entire sentence. </p>

        <p> The Sen2Vec technique has been widely adopted in a variety of NLP applications and has been shown to achieve 
            state-of-the-art results on many benchmark datasets. By enabling the efficient representation of text data in 
            a numerical form, Sen2Vec has opened up new possibilities for NLP research and applications. </p>

        <!-- content sec | HOW IT WORKS -->

        <h2> How the Sen2vec Algorithm Works </h2>

        <p> Sen2Vec is a technique used in natural language processing (NLP) to convert a sequence of words into a 
            mathematical representation. The approach is based on the idea that words that appear in similar contexts are 
            semantically similar. Sen2Vec uses a neural network to learn these contextual relationships between words. The network 
            is trained on large amounts of text data. The trained model can then be used to convert sentences or paragraphs into a 
            vector representation, where each dimension of the vector represents a specific semantic feature. This vector 
            representation can be used for a variety of NLP tasks, such as text classification or information retrieval. </p>

        <p> The Sen2Vec technique has several advantages over traditional NLP techniques that rely on hand-crafted features. 
            Since it learns the context-dependent relationships between words automatically, it can capture subtle semantic 
            relationships that might be missed by other approaches. Additionally, because the technique uses a neural network, 
            it can scale to very large datasets and can be easily trained on new data. Sen2Vec has become a popular technique 
            in NLP and is widely used in applications such as sentiment analysis, document classification, and machine translation. </p>

        <p> The Process of Performing Sen2vec: </p>

        <ul>
            <li>Input Data is fed into sen2vec algorithm </li>
            <li>Creates paragraph IDs and vocabulary, initializing word vectors</li>
            <li>Input matrix is created based on the paragraph ID, context words, and center words </li>
            <li>Word and paragraph weight matrices are initialized along with a bias matrix</li>
            <li>The predicted center word matrix is computed and softmax is applied</li>
            <li>Negative log likelihood loss is calculated using both the predicted center word matrix and the true word matrix</li>
            <li>The adam optimizer is then used to update the word and paragraph weight matrices along with the bias matrices</li>
            <li>The corresponding updated matrices are used in the next epoch</li>
            <li>This process is repeated until optimization is met, resulting in the final paragraph vectors</li>
        </ul>

        <p> The step-by-step simulation provides a more detailed explanation of the individual components of this algorithm. </p>

    </div>
</body>

</html>